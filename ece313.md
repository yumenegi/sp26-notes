# ECE 313
- [ECE 313](#ece-313)
  - [01/20/26](#012026)
    - [TODO](#todo)
  - [01/22/26](#012226)
    - [Motivation](#motivation)
    - [Experimental Analysis](#experimental-analysis)
    - [Basic Steps to solving Problems](#basic-steps-to-solving-problems)
    - [Basic Concepts](#basic-concepts)
    - [Events](#events)
  - [01/24/26](#012426)
    - [Terminology Example](#terminology-example)
    - [Terminology](#terminology)
    - [Describing Probability](#describing-probability)
    - [Rolling Two Dice and Non-Equal Probable Sample Space](#rolling-two-dice-and-non-equal-probable-sample-space)
    - [K-Maps](#k-maps)
    - [Event Axioms](#event-axioms)
    - [Probability Axioms](#probability-axioms)
    - [Counting](#counting)
    - [Principle of Counting for Independent Experiments](#principle-of-counting-for-independent-experiments)
    - [Principle of Counting for Dependent Experiments](#principle-of-counting-for-dependent-experiments)
    - [Permutation](#permutation)
  - [01/27/26](#012726)
    - [Principle of Over Counting](#principle-of-over-counting)
    - [Combination](#combination)
    - [Sample space with infinite cardinality](#sample-space-with-infinite-cardinality)
    - [Random Variables](#random-variables)
  - [01/29/26](#012926)
    - [Probability Mass Function](#probability-mass-function)
    - [Mean](#mean)
    - [Function of RV - LOTUS](#function-of-rv---lotus)
    - [Variance and Standard Deviation](#variance-and-standard-deviation)

## 01/20/26
- Section A is separate from the other sections
  - One less midterm
  - More in class activities and one more project
  - Find teams of three on campuswire

### TODO
- Join gradescope
- Homework
- Find team

## 01/22/26
### Motivation
- Tools to analyze computer systems and the algorithms
  - Distribution of inputs
  - Arrival patterns of tasks
  - Computer resources
- Applications in healthcare, transportation systems, smart power grid
- Probability is used to evaluate system design and performance
  - Throughput
  - Response time
  - Reliability
  - Availability

### Experimental Analysis
- Need to specify various probability distributions
- Sample space
- You can combine probabilities so long they follow the rules of probability

### Basic Steps to solving Problems
1. Identifying the sample space $S$
   1. No two elements can occur simultaneously and one element must occur on any trial
   2. All its elements ar emutually exclusive and coillectively exhaustive
2. Assign probabilities to the elements in $S$
   1. Can be assigned to individual characteristics
   2. Must be consistent with the axioms of probabilties
3. Identity the events of interests
   1. How often/how likely a certain event is going to occur
   2. Developing insight based on probabilities

### Basic Concepts
- **Random Experiment**
  - Outcome is not certain
- **Sample Space**
  - The totality of all possible outcomes
  - Any outcome will happen within the sample space
  - The chance that an outcome will occur is always greater than or equal to 1 (?)
- **Discrete**
  - Countable
  - Countably infinite
- **Continous Sample Space**

### Events
- An event is a collection of certain sample points
  - A subset of the sample space
- An event is defined as a statement whose truth or falsity is determined after the experiment
- e.g. An event is the times a coin toss results in 9 heads out of 10 throws
- The set of all outcomes for which the statement is true defines the subset of the sample space corresponding to the target event
- Elementary event is the event consisting of a single sample point
- $E$ is an event is defined in the sample space $S$
  - $E \subset S$
- Outcome of a specific trial is an element $s$
- If $s$ has occursed, $E$ has occursed
- $s$ may be an element in multiple events
  - Many events may occur
- Universal event is the entire sample space $S$
- The null set $\emptyset$ is a null or impossible event

## 01/24/26
> Section Switch
### Terminology Example
- Experiments
  - Toss a fair coin
- Outcomes
  - Heads or tail
- Trials
  - Do this $x$ times

### Terminology
- Sample Space ($\Omega$)
  - The set of possible outcomes of an experiment
- Event
  - A subset of the sameple space

### Describing Probability
- If every outcome is equally probable
  - $P(A) = \frac{|A|}{|\Omega|}$

### Rolling Two Dice and Non-Equal Probable Sample Space
- Roll two fair dices, probability of the sum being 6
- $\Omega _1 = \{2, 3, 4, ... , 12\}$
- $A _1 = \{7\}$
- We have two construct a new sample space
- $\Omega _2 = \{ [1,1], [1,2], ..., [6,6]\}$
- $A _2 = \{[1,5], [2,4]..., [5,1]\}$

### K-Maps
- Sum of the probability of all the boxes

### Event Axioms
1. $\Omega \in \mathscr{F}$ is an event
2. If $A \in \mathscr{F}$, then $A ^c \in \mathscr{F}$ 
3. If $A \in \mathscr{F}$, $B \in \mathscr{F}$, then $A \cup B \in \mathscr{F}$ 
4. $\emptyset \in \mathscr{F}$
5. If $A \in \mathscr{F}$, $B \in \mathscr{F}$, then $A \cap B \in \mathscr{F}$

### Probability Axioms
1. $\forall A \in \mathscr{F}, P(A) \leq 1$
2. If $A,B \in \mathscr{F}$ and $A,B$ are mutually exclusive then $P(A \cup B) = P(A) + P(B)$
3. $P(\Omega) = 1$
4. $P(A ^c) = 1 - P(A)$
5. $P(A \cup B) = P(A) + P(B) - P(AB)$

### Counting
- Independent Experiments
  - Toss a coin and roll a die
  - Roll a die twice
- Dependent Experiments
  - Bin of balls
  - Draw two balls
  - Pokers
> e.g. Toss a coin and roll a die
> $\Omega _c = \{H,T\}, \Omega _d = \{1,2,3,4,5,6\}$
> $\Omega = \{H1, H2, H3, ... , T1, T2...\}$
> $|\Omega| = |\Omega _c| \times |\Omega _d| = 2 \times 6 = 12$
> $|A| = |\{ H2, H4, H6, T2, T4, T6\}| = |\Omega _c| \times |A _d| = 2 \times 3 = 6$, where $A$ is the event we roll an even number on the die
- **For independent events**, $P(AB) = P(A)P(B)$

### Principle of Counting for Independent Experiments
- If there are $m$ ways to select one variable, and $n$ ways to select the other
- If these variables are selected independently
- Then there are $m \times n$ ways to make the pair of selections

### Principle of Counting for Dependent Experiments
- Drawing socks from 4 pairs of black and 2 pairs white socks
- The first draw affects the second one
- $P(\text{Draw two socks, color is the same})$
- $\Omega _1 = \{ B1, B2, ..., B8, W1, W2, ..., W4\}$
- $A=\{B1B2, B1B3, ..., B7B8, W1,W2, ..., W3W4\}$

### Permutation
- The number of ways to order $n$ different items
- How many ways can you order letters $A, B, C, D$?
  - $|A|=N!$
- What if we want to order $A, B, C, ..., G$ but only pick 4?
  - $|A|= \frac{7!}{3!}$
  - Why divide by $3!$
    - Each unique combinations of the first 4 letters would result in the permutation of $3!$ of the last 3 letters that we do not care about
- What if we want to order letters of ILLINI?
  - We have duplicates
  - $|A|= \frac{6!}{2!3!}$

## 01/27/26
### Principle of Over Counting
- What if we want to order letters of ILLINI?
  - We have duplicates
  - $|A|= \frac{6!}{2!3!}$
    - Over-counting the combinations of I and I and I, they are the same
    - Same thing with L and L
    - We don't care about the permutation of the same characters so we divide it by the duplicates

### Combination
- The number of ways to choose k out of n different items
- $C(n, k)$
- Choose means, we don't care picking orders
  - For example, choosing students out of a class, you don't care abotu the order of the picking
  - As long as in the chosen set
- ${n \choose k} = \frac{n!}{k!(n-k)!}$
  - $k!$: don't care about the k choosed orders
  - $(n-k)!$: don't care about the last items that are not chosen, they are still being ordered by the permutation
- e.g. Draw 3 balls out of 5 balls without replacement
  - ${5 \choose 3} = \frac{5!}{2!3!}$
    - $2!$ is the last two permutations that we don't care about
    - $3!$ is the ordering of the first 3 balls we drew that we don't care about
- e.g. 4 pairs of black socks and 2 pairs of white socks
  - $P(\text{Draw two socks, color is the same})$
    - $|\Omega| = {12 \choose 2}$
    - $|A| = |{A _B}| + |{A _W}| = {8 \choose 2} + {4 \choose 2}$
    - $\frac{|A|}{|\Omega|}$
- e.g. A bag contains {R, R, R, R, G, G, B}, probability of choosing 3 balls of different colour
  - $\frac{4 \times 2 \times 1}{7 \choose 3}$
- e.g. Poker
  - $\Omega _{card} = 52$
  - Full house is 3 same numbers, other 2 same numbers
  - $P(\text{FULL HOUSE}) = \frac{|A _{3kind}| \times |A _{2kind}|}{52 \choose 5}$
  - We can multiply because they are independent events
  - $|A _{3kind}| = {4 \choose 3} {13 \choose 1}$
  - $|A _{2kind}| = {4 \choose 2} {12 \choose 1}$

### Sample space with infinite cardinality
- Interval probability
- $\Omega = \{\omega: 0 \leq \omega \leq 1\},P([a,b])=b-a$
- $A=[0.2, 0.8]$
- Probability of continous intervals
  - $P(x=0.234)=0$

### Random Variables
- Rolling a die $\Omega = \{1,2,3,4,5,6\}$, event "odd" $A=\{1,3,5\}$
  - Add a coated face to the die $[1,0,1,0,1,0]$
  - Coated die X is a "random variable"
- Random Variable
  - A random variable is a real-value funtion on $\Omega$
  - e.g. Mapping head to 1 and tail to 0
  - A random variable $X$ is said to be discrete type if there's a finite/countable infinite set $\{u_1, u_2, ...\}\ s.t.\ P\{X \in \{u_1, u_2, ...\} \}$

## 01/29/26
### Probability Mass Function
- PMF
- Probability that a random variable is equal to a certain number
- $p_x(u)=P\{X=u\}$ for a discrete random variable $X$
- The sum of the probability of all outcomes is 1
- Let $X$ be the outcome of a fair die roll
  - $p_x(2)=\frac{1}{6}$
- PMF can determine probabilities of all events determined by $X$
  - e.g. fair die
    - Map even to -1 and odd to 1
    - Outcomes = {1,2,3,4,5,6}
    - X = {1,-1,1,-1,1,-1}
    - $X$ describes "even" if $X=-1$
    - $X$ does not describe multiples of 3
  - e.g.
    - Voting for favourite number
    - 1  2  3  4  5  6
    - 11 15 22 26 11 15   %
    - Not equally probably
    - $$P(\text{Roll twice and get a pair}) \newline = P([1,1]) + P([2,2]) + P([3,3]) + ... + P([6,6]) \newline = 0.11^2 + ... + 0.15^2$$
  - e.g. Let $S$ be the sum of rolling two dice
    - $S$ is a RV because it is a real value function mapping all outcome
    - $P(S=7)=\frac{6}{36}$
    - $p_s=\{2\rarr \frac{1}{36},..., 6 \rarr \frac{5}{36}, 7 \rarr \frac{6}{36},...\}$
    - $\{(T_i, T_j) | i \neq j, T_i = T_j\}$, we don't need to account for it twice is our probability PMF because it only appears once
  - e.g. Let $N$ be the # of toss until getting first tail
      - Real value function, countably finite
      - $P_N(n)=\frac{1}{2} ^n$
    - Let $M$ be the # of heads observed until getting first tail
    - $M \in [0, \infty]$
    - $P_M(m)=(\frac{1}{2}) ^{m-1}$
  - $M$ & $N$ are depedent variables to each other

### Mean
- In many cases, we don't need detailed PMF
- $\mu _x =E[X]=\Sigma_i a_i p_x(a_i)$
  - For all possible outcome of $X$, we time its outcome with its possibility
- e.g. $X$ is the number for a die roll
- $Y=2X$, $Y$ is a variable that doubles the roll of a die
- $Y \in {2,4,6,8,10,12}$
- $E[Y] = \frac{1}{6} \times 2 + \frac{1}{6} \times 4 + ... + \frac{1}{6} \times 12$
- $Z=|X-3|$
- $Z \in {0,1,2,3}$
- $E[Z]= \frac{1}{6} \times 0 + \frac{2}{6} \times 1 + \frac{2}{6} \times 2 + \frac{1}{6} \times 3 = \frac{3}{2}$

### Function of RV - LOTUS
- $E[g(x)]=\Sigma g(x)p(x)$
- e.g. $X$ is RV uniformly sampled from {-1,0,1,2,3}
  - $p_X(x)=\frac{1}{5}$
  - $Y=X^2$
  - $E[g(x)]=\Sigma g(x)p(x)$
  - $Y=g(x)=\{1,0,1,4,9\}$
  - $E[Y]=\frac{1}{5} \times 1 + \frac{1}{5} \times 0 + \frac{1}{5} \times 1 + \frac{1}{5} \times 4 + \frac{1}{5} \times 9$
- e.g. $X$ is rolling a D6, $Y$ is rolling a D8
- $E[XY]=\Sigma x\cdot y \cdot p(x)p(y)$
- $= xy \frac{1}{6} \frac{1}{8}$
- $= \frac{1}{48} (1+2+3+4+5+6)(1+2+3+4+5+6+7+8)$

### Variance and Standard Deviation
- Variance is how PMF spreads apart from the mean
- $Var(x) \triangleq E[(x-\mu_x)^2]=E[X^2]-(E[X])^2$
- $(x-\mu_x)^2$ is the deviation
- $E[(x-\mu_x)^2] = E[X^2 - 2\mu _x X + \mu _x ^2] = E[X^2]-2\mu_x E[X]+\mu_x^2=E[X^2]-2\mu_x^2+\mu_x^2$
- Standard deviation $\sigma = \sqrt{Var(X)}$
- $Var(X+c) = Var(X)$
- $Var(aX+c) = a^2\times Var(X)$
- e.g. Do you want your monthly salary to be
  - $p_x(10K)=1$
  - $p_y(0)=0.99,p_y(1000K)=0.01$
  - Same expectation
  - What if it's bonus?
